{
    "default": {
        "llm_local": true,
        "model": "gemma3:4b",
        "system_prompt": "Default system prompt from conf_llm.json.",
        "local": {
            "llm_path": "",
            "chat_format": "llama-3",
            "n_gpu_layers": -1,
            "repeat_penalty": 1.5,
            "n_ctx": 4096,
            "temperature": 1.2,
            "top_p": 0.95,
            "top_k": 60,
            "max_tokens": 2048
        }
    }
}